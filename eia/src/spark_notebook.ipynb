{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "####################################\n",
    "# Author: Jon Willinger\n",
    "# Date: 2024-12-09\n",
    "# Notes: \n",
    "# api key registration url: https://www.eia.gov/opendata/register.php (api license terms here).\n",
    "# api key name: Jon Willinger (Can be anyone; email is available to the team).\n",
    "# api key registration email: resinsmartauto@rtiglobal.com\n",
    "# eia front url: https://www.eia.gov/dnav/pet/PET_SUM_SNDW_A_(NA)_YUP_PCT_W.htm\n",
    "#\n",
    "# Notes: Percent Utilization is calculated as gross inputs divided by the latest \n",
    "# reported monthly operable capacity (using unrounded numbers).  See Definitions, \n",
    "# Sources, and Notes link above for more information on this table.\n",
    "#\n",
    "####################################\n",
    "\n",
    "import os\n",
    "import requests\n",
    "from requests.adapters import HTTPAdapter\n",
    "from urllib3.util import Retry\n",
    "import datetime\n",
    "import pandas as pd\n",
    "\n",
    "YUP = \"YUP\"\n",
    "YRL = \"YRL\"\n",
    "GINP = \"EPXXX2\"\n",
    "\n",
    "class eiaapi():\n",
    "\n",
    "    def __init__(self):\n",
    "        def _define_datasets():\n",
    "            dataset=[{\"process\":YUP}, {\"process\":YRL}, {\"product\":GINP}]\n",
    "            return dataset\n",
    "        \n",
    "        self.base_url = \"https://api.eia.gov/v2/petroleum/\"\n",
    "        self.dataset = _define_datasets()\n",
    "        \n",
    "\n",
    "    def get_data(self):\n",
    "\n",
    "        def _execute_calls_get_objects():\n",
    "                # Define the retry strategy.\n",
    "                retry_strategy = Retry(\n",
    "                    total=4,  # Maximum number of retries.\n",
    "                    status_forcelist=[429, 500, 502, 503, 504],  # the HTTP status codes to retry on.\n",
    "                )\n",
    "                \n",
    "                adapter = HTTPAdapter(max_retries=retry_strategy)\n",
    "                \n",
    "                # Create a new session object.\n",
    "                session = requests.Session()\n",
    "                session.mount(\"https://\", adapter)\n",
    "\n",
    "                # gross input: https://api.eia.gov/v2/petroleum/pnp/wiup/data/?frequency=weekly&data[0]=value&facets[product][]=EPXXX2&sort[0][column]=period&sort[0][direction]=desc&offset=0&length=5000\n",
    "                # ref op cap: \n",
    "                responses_dict = {}\n",
    "                for data in self.dataset:\n",
    "                    keys = [k for k in data.keys()]; key = keys[0]\n",
    "                    endpoint = f\"pnp/wiup/data/?api_key={'bOJcg9LVdArsd8Y9f3bhfD2ycNlqck0gIzsoVvzl'}&frequency=weekly&data[0]=value&facets[{key}][]={data[key]}&sort[0][column]=period&sort[0][direction]=desc&offset=0&length=12\"\n",
    "                    url = self.base_url + endpoint\n",
    "                    response = session.get(url)\n",
    "                    status_code = response.status_code\n",
    "                    if status_code == 200:\n",
    "                        print(f\"Success: {status_code}. {url}\")\n",
    "                        responses_dict[data[key]]=response\n",
    "                    else:\n",
    "                         print(f\"Failed: {status_code}. {url}\")\n",
    "                         responses_dict[data[key]] = []\n",
    "\n",
    "                return responses_dict\n",
    "    \n",
    "        def _return_most_recent_friday__from_date(datetime_day):\n",
    "            weekday = datetime_day.weekday()\n",
    "            if weekday < 4: datetime_friday = datetime_day - datetime.timedelta(days=(weekday+3))\n",
    "            elif weekday == 4: datetime_friday = datetime_day\n",
    "            else: datetime_friday = datetime_day - datetime.timedelta(days=(weekday-4))\n",
    "            return datetime_friday\n",
    "\n",
    "        def _process_into_utilization(df_dict):\n",
    "            \n",
    "            def __transform_df_for_azure(df):\n",
    "                '''\n",
    "                    Requires percent-utilization,\n",
    "                    and names.\n",
    "                '''\n",
    "                df_transform = pd.DataFrame({})\n",
    "                for col in df.columns:\n",
    "                    if col == \"period\":\n",
    "                        val = df[col].unique()[0]\n",
    "                        df_transform[\"Date\"] = pd.Series(val)\n",
    "                    if col == \"area-name\":\n",
    "                        tr_cols = [tr_col.replace(\" \", \"\") for tr_col in df[col].to_list()]\n",
    "                    if col == \"percent-utilization\":\n",
    "                        tr_vals = df[col].to_list()\n",
    "\n",
    "                for k, v in zip(tr_cols, tr_vals):\n",
    "                    df_transform[k] = pd.Series(v)\n",
    "                \n",
    "                return df_transform[[\"Date\", \"U.S.\", \"PADD3\"]]\n",
    "\n",
    "            df_yup = pd.DataFrame({})\n",
    "            df_yrl = pd.DataFrame({})\n",
    "            df_ginp = pd.DataFrame({})\n",
    "\n",
    "            for k in df_dict.keys():\n",
    "                if k == YUP: \n",
    "                    df_yup = df_dict[k]\n",
    "                elif k == YRL: \n",
    "                    df_yrl = df_dict[k]\n",
    "                elif k == GINP: \n",
    "                    df_ginp = df_dict[k]\n",
    "\n",
    "            columns = [\"period\", \"duoarea\", \"area-name\", \"series-description\", \"value\", \"units\"]\n",
    "            df_yup_ = df_yup[columns]\n",
    "            area_names = [\"PADD 3\", \"U.S.\"]\n",
    "            merge_columns = columns[0:3]; columns.append(\"product-name\")\n",
    "            df_ = df_yrl.merge(right=df_ginp[columns], how=\"inner\", on=merge_columns, suffixes=(\"\", \".ginp\"))\n",
    "            filter_columns = columns.copy(); filter_columns.extend([\"series-description.ginp\", \"value.ginp\", \"units.ginp\"])\n",
    "            df_eia = df_[filter_columns]\n",
    "            df_eia = df_eia.drop(labels=[\"product-name\"], axis=1)\n",
    "            map_names = {\"series-description\":\"output-description\", \"value\":\"output-value\", \"units\":\"output-units\", \n",
    "                         \"series-description.ginp\":\"input-description\", \"value.ginp\":\"input-value\", \"units.ginp\":\"input-units\"}\n",
    "            map = {\"output-description\":str, \"output-value\":float, \"output-units\":str, \n",
    "                         \"input-description\":str, \"input-value\":float, \"input-units\":str}\n",
    "            df_eia = df_eia.rename(columns=map_names)\n",
    "            df_eia = df_eia.astype(map)\n",
    "            df_eia[\"percent-utilization\"] = (df_eia[\"input-value\"]/df_eia[\"output-value\"])*100\n",
    "            df_eia[\"percent-utilization\"] = df_eia[\"percent-utilization\"].round(2)\n",
    "            \n",
    "            datetime_friday = _return_most_recent_friday__from_date(datetime.datetime.today()); datestr_friday = datetime_friday.strftime(\"%Y-%m-%d\")\n",
    "            datetime_prev_friday = datetime_friday - datetime.timedelta(days=7); datestr_prev_friday = datetime_prev_friday.strftime(\"%Y-%m-%d\")\n",
    "            merge_columns.append(\"percent-utilization\")\n",
    "            df_eia_fil = df_eia[(df_eia[\"period\"]==datetime_friday) & (df_eia[\"area-name\"].isin(area_names))][merge_columns]\n",
    "            if df_eia_fil.empty:\n",
    "                df_eia_fil = df_eia[(df_eia[\"period\"]==datestr_prev_friday) & (df_eia[\"area-name\"].isin(area_names))][merge_columns]\n",
    "            df_eia_fil.reset_index(drop=True, inplace=True)\n",
    "            df_eia_final = __transform_df_for_azure(df_eia_fil)\n",
    "            return df_eia_final\n",
    "\n",
    "        # Entry:\n",
    "        # ``````\n",
    "        responses_dict = _execute_calls_get_objects()\n",
    "        df_dict = {}\n",
    "        for k in responses_dict:\n",
    "            response_object = responses_dict[k]\n",
    "            data_records = response_object.json()[\"response\"][\"data\"]\n",
    "            df = pd.DataFrame(data=data_records)\n",
    "            df_dict[k] = df\n",
    "        \n",
    "        df = _process_into_utilization(df_dict)\n",
    "\n",
    "        return df\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "     eia = eiaapi()\n",
    "\n",
    "     df = eia.get_data()\n",
    "     print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Define connection string parameters:\n",
    "synapse_host = \"rti-synapse-db.sql.azuresynapse.net\"\n",
    "port = 1433\n",
    "db_table = \"stg.RefineryRates\"\n",
    "db_name = \"synapsesqlserver\"\n",
    "linked_service_name = \"rti_synapse_db_pyspark_uami01_ls\"\n",
    "\n",
    "sql_access_token = TokenLibrary.getConnectionString(linked_service_name)\n",
    "\n",
    "# Define connection string:\n",
    "jdbc_url = f\"jdbc:sqlserver://{synapse_host}:{port};database={db_name};encrypt=true;trustServerCertificate=false;hostNameInCertificate=*.sql.azuresynapse.net;loginTimeout=30\"\n",
    "\n",
    "# Define PySpark dataframe:\n",
    "spark = SparkSession.builder.appName(\"ReadWriteEIAToSynapseSQL\").getOrCreate()\n",
    "df_spark = spark.createDataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "col_str = \"Date DATE, `U.S.` FLOAT, PADD3 FLOAT\"\n",
    "df_spark.write \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"url\", jdbc_url) \\\n",
    "    .option(\"dbtable\", db_table) \\\n",
    "    .option(\"accessToken\", sql_access_token) \\\n",
    "    .option(\"createTableColumnTypes\", col_str) \\\n",
    "    .option(\"encrypt\", \"true\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .save() # could also append."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
